{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-22T23:30:50.601282Z",
     "iopub.status.busy": "2025-07-22T23:30:50.601040Z",
     "iopub.status.idle": "2025-07-22T23:30:50.607207Z",
     "shell.execute_reply": "2025-07-22T23:30:50.606625Z",
     "shell.execute_reply.started": "2025-07-22T23:30:50.601251Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Configure your Reddit API credentials here â”€â”€â”€\n",
    "import os\n",
    "os.environ[\"REDDIT_CLIENT_ID\"]     = \"\"  # your client ID\n",
    "os.environ[\"REDDIT_CLIENT_SECRET\"] = \"\"  # your client secret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T23:31:46.230677Z",
     "iopub.status.busy": "2025-07-22T23:31:46.230347Z",
     "iopub.status.idle": "2025-07-22T23:31:46.755949Z",
     "shell.execute_reply": "2025-07-22T23:31:46.755259Z",
     "shell.execute_reply.started": "2025-07-22T23:31:46.230649Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/sportsoracle\n",
      "remote: Enumerating objects: 7, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (4/4), 748 bytes | 748.00 KiB/s, done.\n",
      "From https://github.com/robdreamville/sportsoracle\n",
      " * branch            main       -> FETCH_HEAD\n",
      "   d82feba..47dc96c  main       -> origin/main\n",
      "Updating d82feba..47dc96c\n",
      "Fast-forward\n",
      " src/summarize_trends.py | 26 \u001b[32m+++++++++++++++++++++++++\u001b[m\u001b[31m-\u001b[m\n",
      " 1 file changed, 25 insertions(+), 1 deletion(-)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "project_dir = \"/kaggle/working/sportsoracle\"\n",
    "\n",
    "if not os.path.exists(project_dir):\n",
    "    !git clone https://github.com/robdreamville/sportsoracle.git\n",
    "else:\n",
    "    # Change to the directory first\n",
    "    %cd /kaggle/working/sportsoracle\n",
    "    !git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-22T23:31:48.982388Z",
     "iopub.status.busy": "2025-07-22T23:31:48.981711Z",
     "iopub.status.idle": "2025-07-22T23:33:12.450103Z",
     "shell.execute_reply": "2025-07-22T23:33:12.449362Z",
     "shell.execute_reply.started": "2025-07-22T23:31:48.982352Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/sportsoracle/requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/sportsoracle/requirements.txt (line 3)) (1.2.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/sportsoracle/requirements.txt (line 4)) (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/sportsoracle/requirements.txt (line 5)) (4.52.4)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/sportsoracle/requirements.txt (line 6)) (4.1.0)\n",
      "Collecting langdetect (from -r /kaggle/working/sportsoracle/requirements.txt (line 7))\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting feedparser (from -r /kaggle/working/sportsoracle/requirements.txt (line 8))\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/sportsoracle/requirements.txt (line 9)) (4.67.1)\n",
      "Collecting python-dotenv (from -r /kaggle/working/sportsoracle/requirements.txt (line 10))\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting praw (from -r /kaggle/working/sportsoracle/requirements.txt (line 11))\n",
      "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting faiss-cpu (from -r /kaggle/working/sportsoracle/requirements.txt (line 12))\n",
      "  Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/sportsoracle/requirements.txt (line 13)) (3.6.0)\n",
      "Collecting bertopic (from -r /kaggle/working/sportsoracle/requirements.txt (line 16))\n",
      "  Downloading bertopic-0.17.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: hdbscan in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/sportsoracle/requirements.txt (line 17)) (0.8.40)\n",
      "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/sportsoracle/requirements.txt (line 18)) (0.5.7)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/sportsoracle/requirements.txt (line 21)) (3.9.1)\n",
      "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/working/sportsoracle/requirements.txt (line 22)) (0.9.3)\n",
      "Collecting streamlit (from -r /kaggle/working/sportsoracle/requirements.txt (line 26))\n",
      "  Downloading streamlit-1.47.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->-r /kaggle/working/sportsoracle/requirements.txt (line 2)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->-r /kaggle/working/sportsoracle/requirements.txt (line 2)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->-r /kaggle/working/sportsoracle/requirements.txt (line 2)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->-r /kaggle/working/sportsoracle/requirements.txt (line 2)) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->-r /kaggle/working/sportsoracle/requirements.txt (line 2)) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->-r /kaggle/working/sportsoracle/requirements.txt (line 2)) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /kaggle/working/sportsoracle/requirements.txt (line 3)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /kaggle/working/sportsoracle/requirements.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /kaggle/working/sportsoracle/requirements.txt (line 3)) (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (0.33.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 6)) (11.2.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect->-r /kaggle/working/sportsoracle/requirements.txt (line 7)) (1.17.0)\n",
      "Collecting sgmllib3k (from feedparser->-r /kaggle/working/sportsoracle/requirements.txt (line 8))\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting prawcore<3,>=2.4 (from praw->-r /kaggle/working/sportsoracle/requirements.txt (line 11))\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw->-r /kaggle/working/sportsoracle/requirements.txt (line 11)) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw->-r /kaggle/working/sportsoracle/requirements.txt (line 11)) (1.8.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (0.70.16)\n",
      "Collecting fsspec (from torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4))\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic->-r /kaggle/working/sportsoracle/requirements.txt (line 16)) (5.24.1)\n",
      "Requirement already satisfied: llvmlite>0.36.0 in /usr/local/lib/python3.11/dist-packages (from bertopic->-r /kaggle/working/sportsoracle/requirements.txt (line 16)) (0.43.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn->-r /kaggle/working/sportsoracle/requirements.txt (line 18)) (0.60.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn->-r /kaggle/working/sportsoracle/requirements.txt (line 18)) (0.5.13)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->-r /kaggle/working/sportsoracle/requirements.txt (line 21)) (8.2.1)\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext->-r /kaggle/working/sportsoracle/requirements.txt (line 22)) (2.13.6)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext->-r /kaggle/working/sportsoracle/requirements.txt (line 22)) (75.2.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (5.5.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (3.20.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (3.1.44)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (6.5.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (4.24.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (1.44.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (3.12.13)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (4.0.12)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (2025.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r /kaggle/working/sportsoracle/requirements.txt (line 4)) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r /kaggle/working/sportsoracle/requirements.txt (line 5)) (2025.6.15)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r /kaggle/working/sportsoracle/requirements.txt (line 2)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r /kaggle/working/sportsoracle/requirements.txt (line 2)) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->-r /kaggle/working/sportsoracle/requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->-r /kaggle/working/sportsoracle/requirements.txt (line 2)) (2024.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /kaggle/working/sportsoracle/requirements.txt (line 13)) (1.20.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (5.0.2)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->-r /kaggle/working/sportsoracle/requirements.txt (line 2)) (2024.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /kaggle/working/sportsoracle/requirements.txt (line 26)) (0.25.1)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bertopic-0.17.3-py3-none-any.whl (153 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading streamlit-1.47.0-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: langdetect, sgmllib3k\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=66a65b8c3e1a23ecd7d2ab104cc72bd0e2e2bbbf9c2d53fa9bd10494778bd7f0\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=3fedb085886248a417be6863dccbcaf252547ffa8d66dc10a43e3cc4fedb7015\n",
      "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
      "Successfully built langdetect sgmllib3k\n",
      "Installing collected packages: sgmllib3k, python-dotenv, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, langdetect, fsspec, feedparser, prawcore, nvidia-cusparse-cu12, nvidia-cudnn-cu12, praw, nvidia-cusolver-cu12, pydeck, streamlit, faiss-cpu, bertopic\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bertopic-0.17.3 faiss-cpu-1.11.0.post1 feedparser-6.0.11 fsspec-2025.3.0 langdetect-1.0.9 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 praw-7.8.1 prawcore-2.4.0 pydeck-0.9.1 python-dotenv-1.1.1 sgmllib3k-1.0.0 streamlit-1.47.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /kaggle/working/sportsoracle/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T23:34:43.454401Z",
     "iopub.status.busy": "2025-07-22T23:34:43.454148Z",
     "iopub.status.idle": "2025-07-22T23:41:18.714038Z",
     "shell.execute_reply": "2025-07-22T23:41:18.713304Z",
     "shell.execute_reply.started": "2025-07-22T23:34:43.454384Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-22 23:34:54.837220: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753227295.000500     133 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753227295.047341     133 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Downloading FastText language identification model...\n",
      "Model downloaded successfully.\n",
      "\n",
      "ğŸš€ Running full SportsOracle pipeline...\n",
      "\n",
      "[1/5] Scraping Reddit and ESPN data...\n",
      "\n",
      "ğŸ”´ Scraping Reddit postsâ€¦\n",
      "Scraping r/soccer: 50it [00:00, 68.00it/s]\n",
      "Scraping r/football: 50it [00:00, 74.89it/s]\n",
      "Scraping r/PremierLeague: 50it [00:00, 58.80it/s]\n",
      "Scraping r/ChampionsLeague: 50it [00:00, 97.64it/s]\n",
      "Scraping r/LaLiga: 50it [00:00, 58.22it/s]\n",
      "Scraping r/SerieA: 50it [00:00, 59.97it/s]\n",
      "Scraping r/Bundesliga: 50it [00:00, 77.09it/s]\n",
      "Scraping r/Ligue1: 50it [00:01, 37.36it/s]\n",
      "Scraping r/nba: 50it [00:00, 60.32it/s]\n",
      "Scraping r/NBATalk: 50it [00:00, 67.15it/s]\n",
      "Scraping r/nba_draft: 50it [00:00, 53.75it/s]\n",
      "Scraping r/nbacirclejerk: 50it [00:00, 53.49it/s]\n",
      "Scraping r/nbadiscussion: 50it [00:00, 56.62it/s]\n",
      "âœ… 641 posts saved to /kaggle/working/sportsoracle/data/raw_posts.json and /kaggle/working/sportsoracle/data/raw_reddit.jsonl\n",
      "\n",
      "ğŸ”µ Scraping ESPN RSSâ€¦\n",
      "Scraping ESPN NBA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 107546.26it/s]\n",
      "Scraping ESPN Soccer: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 138527.47it/s]\n",
      "âœ… Saved 30 ESPN items to /kaggle/working/sportsoracle/data/raw_espn.json and /kaggle/working/sportsoracle/data/raw_espn.jsonl\n",
      "âœ… Reddit JSONL written to /kaggle/working/sportsoracle/data/raw_reddit.jsonl\n",
      "âœ… ESPN JSONL written to /kaggle/working/sportsoracle/data/raw_espn.jsonl\n",
      "âœ… Combined JSONL written to /kaggle/working/sportsoracle/data/raw_combined.jsonl\n",
      "\n",
      "ğŸ”— Combined 671 items â†’ /kaggle/working/sportsoracle/data/raw_combined.json\n",
      "âœ… Scraping complete!\n",
      "\n",
      "[2/5] Normalizing language and translating posts to English...\n",
      "Generating train split: 671 examples [00:00, 27476.38 examples/s]\n",
      "Map:   0%|                                       | 0/671 [00:00<?, ? examples/s]\n",
      "config.json: 1.38kB [00:00, 7.06MB/s]\n",
      "\n",
      "pytorch_model.bin:   0%|                             | 0.00/309M [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model.bin:   7%|â–ˆâ–                   | 21.0M/309M [00:00<00:02, 144MB/s]\u001b[A\n",
      "pytorch_model.bin:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–                | 62.9M/309M [00:00<00:01, 240MB/s]\u001b[A\n",
      "pytorch_model.bin:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 94.4M/309M [00:00<00:00, 264MB/s]\u001b[A\n",
      "pytorch_model.bin:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 136M/309M [00:00<00:00, 284MB/s]\u001b[A\n",
      "pytorch_model.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 168M/309M [00:00<00:00, 289MB/s]\u001b[A\n",
      "pytorch_model.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 199M/309M [00:00<00:00, 292MB/s]\u001b[A\n",
      "pytorch_model.bin:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 231M/309M [00:00<00:00, 291MB/s]\u001b[A\n",
      "pytorch_model.bin:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 262M/309M [00:00<00:00, 295MB/s]\u001b[A\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 309M/309M [00:01<00:00, 277MB/s]\u001b[A\n",
      "\n",
      "generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 293/293 [00:00<00:00, 2.87MB/s]\u001b[A\n",
      "\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.0/42.0 [00:00<00:00, 371kB/s]\u001b[A\n",
      "\n",
      "model.safetensors:   0%|                             | 0.00/309M [00:00<?, ?B/s]\u001b[A\n",
      "model.safetensors:   3%|â–‹                   | 10.5M/309M [00:00<00:03, 79.8MB/s]\u001b[A\n",
      "\n",
      "source.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 835k/835k [00:00<00:00, 22.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:   7%|â–ˆâ–                  | 21.0M/309M [00:00<00:03, 80.0MB/s]\u001b[A\n",
      "\n",
      "target.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785k/785k [00:00<00:00, 158MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  10%|â–ˆâ–ˆ                  | 31.5M/309M [00:00<00:03, 82.2MB/s]\u001b[A\n",
      "\n",
      "vocab.json: 1.52MB [00:00, 163MB/s][A\n",
      "\n",
      "model.safetensors:  14%|â–ˆâ–ˆâ–‹                 | 41.9M/309M [00:00<00:03, 81.5MB/s]\u001b[A\n",
      "model.safetensors:  17%|â–ˆâ–ˆâ–ˆâ–                | 52.4M/309M [00:00<00:03, 81.2MB/s]\u001b[A\n",
      "model.safetensors:  20%|â–ˆâ–ˆâ–ˆâ–ˆ                | 62.9M/309M [00:00<00:03, 81.0MB/s]\u001b[A\n",
      "model.safetensors:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 73.4M/309M [00:00<00:02, 80.6MB/s]\u001b[ADevice set to use cuda:0\n",
      "\n",
      "model.safetensors:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 83.9M/309M [00:01<00:03, 69.4MB/s]\u001b[A\n",
      "model.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 105M/309M [00:01<00:02, 83.8MB/s]\u001b[A\n",
      "model.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 115M/309M [00:01<00:02, 82.8MB/s]\u001b[A\n",
      "\n",
      "Translating pl:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "model.safetensors:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 126M/309M [00:01<00:02, 67.0MB/s]\u001b[A\n",
      "model.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 147M/309M [00:01<00:01, 86.1MB/s]\u001b[A\n",
      "model.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 157M/309M [00:01<00:01, 85.2MB/s]\u001b[A\n",
      "model.safetensors:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 168M/309M [00:02<00:01, 83.9MB/s]\u001b[A\n",
      "model.safetensors:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 178M/309M [00:02<00:01, 82.0MB/s]\u001b[A\n",
      "model.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 189M/309M [00:02<00:01, 82.1MB/s]\u001b[A\n",
      "model.safetensors:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 199M/309M [00:02<00:01, 82.3MB/s]\u001b[A\n",
      "model.safetensors:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 210M/309M [00:02<00:01, 81.5MB/s]\u001b[A\n",
      "\n",
      "Translating pl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Translating pl: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Translating pl: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Translating pl:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "model.safetensors:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 220M/309M [00:02<00:01, 81.2MB/s]\u001b[A\n",
      "model.safetensors:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/309M [00:02<00:00, 81.0MB/s]\u001b[A\n",
      "model.safetensors:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 241M/309M [00:02<00:00, 80.4MB/s]\u001b[A\n",
      "\n",
      "Translating pl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.81it/s]\u001b[A\u001b[A\n",
      "Map:   5%|â–ˆâ–                            | 32/671 [00:05<01:56,  5.48 examples/s]\n",
      "model.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 252M/309M [00:03<00:00, 81.1MB/s]\u001b[A\n",
      "\n",
      "config.json: 1.36kB [00:00, 7.77MB/s]A\n",
      "\n",
      "model.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 262M/309M [00:03<00:00, 80.7MB/s]\u001b[A\n",
      "model.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 273M/309M [00:03<00:00, 80.3MB/s]\u001b[A\n",
      "model.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 283M/309M [00:03<00:00, 81.3MB/s]\u001b[A\n",
      "\n",
      "pytorch_model.bin:   0%|                             | 0.00/312M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "model.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 294M/309M [00:03<00:00, 79.1MB/s]\u001b[A\n",
      "\n",
      "pytorch_model.bin:   7%|â–ˆâ–                   | 21.0M/312M [00:00<00:01, 158MB/s]\u001b[A\u001b[A\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 309M/309M [00:03<00:00, 80.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model.bin:  17%|â–ˆâ–ˆâ–ˆâ–Œ                 | 52.4M/312M [00:00<00:01, 201MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 83.9M/312M [00:00<00:00, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 115M/312M [00:00<00:00, 251MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 147M/312M [00:00<00:00, 257MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 178M/312M [00:00<00:00, 257MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 210M/312M [00:00<00:00, 259MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 241M/312M [00:00<00:00, 271MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 273M/312M [00:01<00:00, 277MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 312M/312M [00:01<00:00, 249MB/s]\u001b[A\u001b[A\n",
      "\n",
      "generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 293/293 [00:00<00:00, 3.50MB/s]\u001b[A\n",
      "\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 265/265 [00:00<00:00, 2.64MB/s]\u001b[A\n",
      "\n",
      "source.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800k/800k [00:00<00:00, 178MB/s]\u001b[A\n",
      "\n",
      "model.safetensors:   0%|                             | 0.00/312M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "target.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 779k/779k [00:00<00:00, 237MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:   3%|â–‹                   | 10.5M/312M [00:00<00:03, 78.1MB/s]\u001b[A\n",
      "\n",
      "vocab.json: 1.46MB [00:00, 135MB/s][A\n",
      "\n",
      "model.safetensors:   7%|â–ˆâ–                  | 21.0M/312M [00:00<00:03, 82.1MB/s]\u001b[A\n",
      "model.safetensors:  10%|â–ˆâ–ˆ                  | 31.5M/312M [00:00<00:03, 85.8MB/s]\u001b[A\n",
      "model.safetensors:  13%|â–ˆâ–ˆâ–‹                 | 41.9M/312M [00:00<00:03, 80.8MB/s]\u001b[ADevice set to use cuda:0\n",
      "\n",
      "model.safetensors:  17%|â–ˆâ–ˆâ–ˆâ–                | 52.4M/312M [00:00<00:04, 58.5MB/s]\u001b[A\n",
      "\n",
      "Translating pt:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "model.safetensors:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 73.4M/312M [00:01<00:04, 52.2MB/s]\u001b[A\n",
      "model.safetensors:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 83.9M/312M [00:01<00:04, 51.9MB/s]\u001b[A\n",
      "\n",
      "Translating pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Translating pt: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Translating pt: 0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Translating pt:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "model.safetensors:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 94.4M/312M [00:01<00:04, 46.7MB/s]\u001b[A\n",
      "\n",
      "Translating pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.29it/s]\u001b[A\u001b[A\n",
      "Map:   7%|â–ˆâ–ˆâ–                           | 48/671 [00:10<02:24,  4.32 examples/s]\n",
      "model.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 105M/312M [00:01<00:04, 43.9MB/s]\u001b[A\n",
      "\n",
      "config.json: 1.38kB [00:00, 7.03MB/s]A\n",
      "\n",
      "model.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 115M/312M [00:02<00:04, 42.2MB/s]\u001b[A\n",
      "\n",
      "pytorch_model.bin:   0%|                             | 0.00/291M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin:  11%|â–ˆâ–ˆâ–                  | 31.5M/291M [00:00<00:00, 293MB/s]\u001b[A\u001b[A\n",
      "model.safetensors:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 126M/312M [00:02<00:04, 39.8MB/s]\u001b[A\n",
      "\n",
      "pytorch_model.bin:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 62.9M/291M [00:00<00:00, 298MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 94.4M/291M [00:00<00:00, 297MB/s]\u001b[A\u001b[A\n",
      "model.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 136M/312M [00:02<00:04, 39.5MB/s]\u001b[A\n",
      "\n",
      "pytorch_model.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 126M/291M [00:00<00:00, 298MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 157M/291M [00:00<00:00, 300MB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model.bin:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 189M/291M [00:00<00:00, 291MB/s]\u001b[A\u001b[A\n",
      "model.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 147M/312M [00:03<00:04, 40.0MB/s]\u001b[A\n",
      "\n",
      "pytorch_model.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 220M/291M [00:00<00:00, 295MB/s]\u001b[A\u001b[A\n",
      "model.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 157M/312M [00:03<00:03, 45.2MB/s]\u001b[A\n",
      "\n",
      "pytorch_model.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 252M/291M [00:00<00:00, 299MB/s]\u001b[A\u001b[A\n",
      "model.safetensors:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 168M/312M [00:03<00:02, 52.8MB/s]\u001b[A\n",
      "\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 291M/291M [00:00<00:00, 297MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰         | 178M/312M [00:03<00:02, 59.5MB/s]\u001b[A\n",
      "model.safetensors:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 189M/312M [00:03<00:02, 52.4MB/s]\u001b[A\n",
      "model.safetensors:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 199M/312M [00:04<00:02, 46.3MB/s]\u001b[A\n",
      "\n",
      "generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 293/293 [00:00<00:00, 1.94MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 220M/312M [00:04<00:01, 70.2MB/s]\u001b[A\n",
      "\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.0/42.0 [00:00<00:00, 293kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 252M/312M [00:04<00:00, 96.3MB/s]\u001b[A\n",
      "\n",
      "model.safetensors:   0%|                             | 0.00/291M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "source.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 801k/801k [00:00<00:00, 239MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   4%|â–‹                   | 10.5M/291M [00:00<00:02, 99.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "target.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 796k/796k [00:00<00:00, 195MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  11%|â–ˆâ–ˆâ–                  | 31.5M/291M [00:00<00:01, 143MB/s]\u001b[A\u001b[A\n",
      "model.safetensors:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 273M/312M [00:04<00:00, 72.7MB/s]\u001b[A\n",
      "\n",
      "model.safetensors:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 62.9M/291M [00:00<00:01, 207MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "vocab.json: 1.26MB [00:00, 58.8MB/s]A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 94.4M/291M [00:00<00:00, 244MB/s]\u001b[A\u001b[A\n",
      "model.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 304M/312M [00:04<00:00, 95.4MB/s]\u001b[A\n",
      "\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 312M/312M [00:05<00:00, 61.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 157M/291M [00:00<00:00, 268MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 199M/291M [00:00<00:00, 287MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 231M/291M [00:00<00:00, 294MB/s]\u001b[A\u001b[ADevice set to use cuda:0\n",
      "\n",
      "\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 291M/291M [00:01<00:00, 237MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Translating id:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating id: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.69it/s]\u001b[A\n",
      "\n",
      "Translating id: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.36it/s]\u001b[A\n",
      "\n",
      "Translating id: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating id:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating id: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.79it/s]\u001b[A\n",
      "Map:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 176/671 [00:15<00:34, 14.32 examples/s]\n",
      "config.json: 1.38kB [00:00, 8.74MB/s]\n",
      "\n",
      "pytorch_model.bin:   0%|                             | 0.00/298M [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model.bin:   0%|                      | 226k/298M [00:00<20:07, 246kB/s]\u001b[A\n",
      "pytorch_model.bin:  15%|â–ˆâ–ˆâ–ˆ                 | 45.1M/298M [00:01<00:07, 35.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 112M/298M [00:01<00:01, 97.7MB/s]\u001b[A\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298M/298M [00:01<00:00, 162MB/s]\u001b[A\n",
      "\n",
      "generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 293/293 [00:00<00:00, 2.55MB/s]\u001b[A\n",
      "\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.0/42.0 [00:00<00:00, 466kB/s]\u001b[A\n",
      "\n",
      "model.safetensors:   0%|                             | 0.00/298M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "source.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 797k/797k [00:00<00:00, 242MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "target.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 768k/768k [00:00<00:00, 217MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "vocab.json: 1.27MB [00:00, 158MB/s][A\n",
      "\n",
      "model.safetensors:   0%|                      | 754k/298M [00:00<06:18, 786kB/s]\u001b[ADevice set to use cuda:0\n",
      "\n",
      "model.safetensors:   3%|â–Œ                   | 7.97M/298M [00:01<00:28, 10.0MB/s]\u001b[A\n",
      "model.safetensors:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 84.5M/298M [00:01<00:01, 126MB/s]\u001b[A\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298M/298M [00:01<00:00, 211MB/s]\u001b[A\n",
      "\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.01it/s]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.05it/s]\u001b[A\n",
      "\n",
      "Translating de: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.47it/s]\u001b[A\n",
      "Map:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 192/671 [00:20<00:49,  9.72 examples/s]\n",
      "config.json: 1.44kB [00:00, 9.39MB/s]\n",
      "\n",
      "pytorch_model.bin:   0%|                             | 0.00/312M [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model.bin:  14%|â–ˆâ–ˆâ–Š                 | 43.0M/312M [00:01<00:09, 28.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 110M/312M [00:01<00:02, 83.7MB/s]\u001b[A\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 312M/312M [00:01<00:00, 161MB/s]\u001b[A\n",
      "\n",
      "generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 293/293 [00:00<00:00, 2.16MB/s]\u001b[A\n",
      "\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.0/44.0 [00:00<00:00, 443kB/s]\u001b[A\n",
      "\n",
      "source.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 826k/826k [00:00<00:00, 134MB/s]\u001b[A\n",
      "\n",
      "model.safetensors:   0%|                             | 0.00/312M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "target.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 802k/802k [00:00<00:00, 235MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "vocab.json: 1.59MB [00:00, 140MB/s][A\n",
      "Device set to use cuda:0\n",
      "\n",
      "model.safetensors:  14%|â–ˆâ–ˆâ–Š                 | 43.9M/312M [00:01<00:08, 31.7MB/s]\u001b[A\n",
      "\n",
      "Translating es:   0%|                                     | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "model.safetensors:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 111M/312M [00:01<00:02, 83.4MB/s]\u001b[A\n",
      "model.safetensors:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 178M/312M [00:01<00:00, 138MB/s]\u001b[A\n",
      "\n",
      "Translating es:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 1/3 [00:00<00:00,  4.26it/s]\u001b[A\u001b[A\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 312M/312M [00:01<00:00, 160MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Translating es:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 2/3 [00:00<00:00,  4.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Translating es:   0%|                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Translating es:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 1/2 [00:00<00:00,  2.62it/s]\u001b[A\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.74s/it]\u001b[A\n",
      "\n",
      "Translating es: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating es:   0%|                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Translating es:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 1/3 [00:00<00:00,  2.73it/s]\u001b[A\n",
      "Translating es:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 2/3 [00:00<00:00,  4.35it/s]\u001b[A\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.26s/it]\u001b[A\n",
      "Map:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 208/671 [00:33<01:39,  4.67 examples/s]\n",
      "Translating es:   0%|                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Translating es:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 1/4 [00:00<00:00,  4.73it/s]\u001b[A\n",
      "Translating es:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 2/4 [00:00<00:00,  3.93it/s]\u001b[AYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "\n",
      "Translating es:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 3/4 [00:00<00:00,  4.40it/s]\u001b[A\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  4.76it/s]\u001b[A\n",
      "\n",
      "Translating es:   0%|                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Translating es:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 1/2 [00:01<00:01,  1.72s/it]\u001b[A\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.01s/it]\u001b[A\n",
      "\n",
      "Translating es: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating es:   0%|                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Translating es:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 1/4 [00:01<00:05,  1.71s/it]\u001b[A\n",
      "Translating es:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 2/4 [00:02<00:01,  1.13it/s]\u001b[A\n",
      "Translating es:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 3/4 [00:02<00:00,  1.76it/s]\u001b[A\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.55it/s]\u001b[A\n",
      "Map:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 224/671 [00:39<01:46,  4.22 examples/s]\n",
      "Translating es:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.31it/s]\u001b[A\n",
      "\n",
      "Translating es: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating es: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating es:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.20it/s]\u001b[A\n",
      "Map:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 240/671 [00:39<01:22,  5.23 examples/s]\n",
      "config.json: 1.38kB [00:00, 8.42MB/s]\n",
      "\n",
      "pytorch_model.bin:   0%|                             | 0.00/344M [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model.bin:   6%|â–ˆâ–                   | 21.0M/344M [00:00<00:02, 122MB/s]\u001b[A\n",
      "pytorch_model.bin:  15%|â–ˆâ–ˆâ–ˆâ–                 | 52.4M/344M [00:00<00:01, 187MB/s]\u001b[A\n",
      "pytorch_model.bin:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 83.9M/344M [00:00<00:01, 230MB/s]\u001b[A\n",
      "pytorch_model.bin:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 115M/344M [00:00<00:00, 257MB/s]\u001b[A\n",
      "pytorch_model.bin:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 147M/344M [00:00<00:00, 273MB/s]\u001b[A\n",
      "pytorch_model.bin:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 178M/344M [00:00<00:00, 284MB/s]\u001b[A\n",
      "pytorch_model.bin:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 210M/344M [00:00<00:00, 289MB/s]\u001b[A\n",
      "pytorch_model.bin:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 241M/344M [00:00<00:00, 290MB/s]\u001b[A\n",
      "pytorch_model.bin:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273M/344M [00:01<00:00, 293MB/s]\u001b[A\n",
      "pytorch_model.bin:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 304M/344M [00:01<00:00, 293MB/s]\u001b[A\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 344M/344M [00:01<00:00, 267MB/s]\u001b[A\n",
      "\n",
      "generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 293/293 [00:00<00:00, 2.80MB/s]\u001b[A\n",
      "\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.0/42.0 [00:00<00:00, 423kB/s]\u001b[A\n",
      "\n",
      "model.safetensors:   0%|                             | 0.00/344M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "source.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 814k/814k [00:00<00:00, 221MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:   3%|â–Œ                   | 10.5M/344M [00:00<00:08, 41.4MB/s]\u001b[A\n",
      "\n",
      "target.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 790k/790k [00:00<00:00, 213MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  12%|â–ˆâ–ˆâ–Œ                  | 41.9M/344M [00:00<00:02, 138MB/s]\u001b[A\n",
      "\n",
      "vocab.json: 2.37MB [00:00, 158MB/s][A\n",
      "\n",
      "model.safetensors:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–                | 73.4M/344M [00:00<00:01, 196MB/s]\u001b[A\n",
      "model.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 115M/344M [00:00<00:00, 248MB/s]\u001b[A\n",
      "model.safetensors:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 157M/344M [00:00<00:00, 273MB/s]\u001b[A\n",
      "model.safetensors:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 199M/344M [00:00<00:00, 295MB/s]\u001b[A\n",
      "model.safetensors:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 231M/344M [00:00<00:00, 280MB/s]\u001b[A\n",
      "model.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 273M/344M [00:01<00:00, 294MB/s]\u001b[ADevice set to use cuda:0\n",
      "\n",
      "model.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 315M/344M [00:01<00:00, 228MB/s]\u001b[A\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 344M/344M [00:01<00:00, 233MB/s]\u001b[A\n",
      "\n",
      "Translating it:   0%|                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Translating it:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 1/3 [00:00<00:00,  4.31it/s]\u001b[A\n",
      "Translating it:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 2/3 [00:00<00:00,  4.64it/s]\u001b[A\n",
      "Translating it: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.27it/s]\u001b[A\n",
      "\n",
      "Translating it:   0%|                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Translating it:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 1/2 [00:01<00:01,  1.32s/it]\u001b[A\n",
      "Translating it: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.05s/it]\u001b[A\n",
      "\n",
      "Translating it: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating it:   0%|                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Translating it:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 1/3 [00:00<00:00,  4.34it/s]\u001b[A\n",
      "Translating it:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 2/3 [00:01<00:00,  1.10it/s]\u001b[A\n",
      "Translating it: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.18it/s]\u001b[A\n",
      "Map:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 272/671 [00:49<01:33,  4.29 examples/s]\n",
      "Translating de:   0%|                                     | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de:  11%|â–ˆâ–ˆâ–ˆâ–                         | 1/9 [00:00<00:01,  4.20it/s]\u001b[A\n",
      "Translating de:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 2/9 [00:00<00:03,  2.28it/s]\u001b[A\n",
      "Translating de:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 3/9 [00:01<00:03,  1.67it/s]\u001b[A\n",
      "Translating de:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 4/9 [00:01<00:02,  2.17it/s]\u001b[A\n",
      "Translating de:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 5/9 [00:02<00:01,  2.68it/s]\u001b[A\n",
      "Translating de:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 6/9 [00:02<00:01,  2.11it/s]\u001b[A\n",
      "Translating de:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 7/9 [00:02<00:00,  2.55it/s]\u001b[A\n",
      "Translating de:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 8/9 [00:03<00:00,  2.70it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s]\u001b[A\n",
      "\n",
      "Translating de: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                     | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de:  11%|â–ˆâ–ˆâ–ˆâ–                         | 1/9 [00:00<00:01,  4.18it/s]\u001b[A\n",
      "Translating de:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 2/9 [00:00<00:03,  2.27it/s]\u001b[A\n",
      "Translating de:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 3/9 [00:01<00:03,  1.62it/s]\u001b[A\n",
      "Translating de:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 4/9 [00:02<00:03,  1.29it/s]\u001b[A\n",
      "Translating de:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 5/9 [00:02<00:02,  1.75it/s]\u001b[A\n",
      "Translating de:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 6/9 [00:03<00:01,  1.66it/s]\u001b[A\n",
      "Translating de:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 7/9 [00:03<00:00,  2.08it/s]\u001b[A\n",
      "Translating de:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 8/9 [00:04<00:00,  2.32it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:04<00:00,  2.09it/s]\u001b[A\n",
      "Map:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 304/671 [00:57<01:30,  4.07 examples/s]\n",
      "Translating de:   0%|                                    | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de:   7%|â–ˆâ–ˆ                          | 1/14 [00:00<00:09,  1.31it/s]\u001b[A\n",
      "Translating de:  14%|â–ˆâ–ˆâ–ˆâ–ˆ                        | 2/14 [00:01<00:07,  1.50it/s]\u001b[A\n",
      "Translating de:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 3/14 [00:01<00:04,  2.29it/s]\u001b[A\n",
      "Translating de:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 4/14 [00:01<00:04,  2.29it/s]\u001b[A\n",
      "Translating de:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 5/14 [00:02<00:03,  2.56it/s]\u001b[A\n",
      "Translating de:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 6/14 [00:02<00:02,  3.03it/s]\u001b[A\n",
      "Translating de:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 7/14 [00:02<00:01,  3.58it/s]\u001b[A\n",
      "Translating de:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 8/14 [00:02<00:01,  3.56it/s]\u001b[A\n",
      "Translating de:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 9/14 [00:03<00:02,  2.20it/s]\u001b[A\n",
      "Translating de:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 10/14 [00:03<00:01,  2.83it/s]\u001b[A\n",
      "Translating de:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/14 [00:04<00:01,  2.99it/s]\u001b[A\n",
      "Translating de:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 12/14 [00:05<00:00,  2.06it/s]\u001b[A\n",
      "Translating de:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 13/14 [00:05<00:00,  1.83it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.35it/s]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 1/3 [00:00<00:00,  2.74it/s]\u001b[A\n",
      "Translating de:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 2/3 [00:03<00:01,  1.78s/it]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.15s/it]\u001b[A\n",
      "\n",
      "Translating de: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                    | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de:   7%|â–ˆâ–ˆ                          | 1/14 [00:00<00:10,  1.30it/s]\u001b[A\n",
      "Translating de:  14%|â–ˆâ–ˆâ–ˆâ–ˆ                        | 2/14 [00:01<00:08,  1.49it/s]\u001b[A\n",
      "Map:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 304/671 [01:08<01:30,  4.07 examples/s]\u001b[A\n",
      "Translating de:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 4/14 [00:02<00:05,  1.74it/s]\u001b[A\n",
      "Translating de:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 5/14 [00:02<00:04,  2.09it/s]\u001b[A\n",
      "Translating de:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 6/14 [00:02<00:03,  2.57it/s]\u001b[A\n",
      "Translating de:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 7/14 [00:05<00:08,  1.28s/it]\u001b[A\n",
      "Translating de:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 8/14 [00:06<00:05,  1.04it/s]\u001b[A\n",
      "Translating de:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 9/14 [00:07<00:04,  1.08it/s]\u001b[A\n",
      "Translating de:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 10/14 [00:07<00:03,  1.30it/s]\u001b[A\n",
      "Translating de:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/14 [00:07<00:01,  1.59it/s]\u001b[A\n",
      "Translating de:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 12/14 [00:08<00:01,  1.45it/s]\u001b[A\n",
      "Translating de:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 13/14 [00:09<00:00,  1.46it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:09<00:00,  1.47it/s]\u001b[A\n",
      "Map:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 320/671 [01:16<02:31,  2.32 examples/s]\n",
      "Translating de:   0%|                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de:   7%|â–ˆâ–Š                          | 1/15 [00:00<00:07,  1.91it/s]\u001b[A\n",
      "Translating de:  13%|â–ˆâ–ˆâ–ˆâ–‹                        | 2/15 [00:00<00:06,  2.02it/s]\u001b[A\n",
      "Translating de:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 3/15 [00:01<00:07,  1.68it/s]\u001b[A\n",
      "Translating de:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 4/15 [00:01<00:05,  2.17it/s]\u001b[A\n",
      "Translating de:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 5/15 [00:02<00:05,  1.79it/s]\u001b[A\n",
      "Translating de:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 6/15 [00:03<00:04,  1.82it/s]\u001b[A\n",
      "Translating de:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 7/15 [00:03<00:04,  1.68it/s]\u001b[A\n",
      "Translating de:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 9/15 [00:04<00:02,  2.89it/s]\u001b[A\n",
      "Translating de:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 10/15 [00:04<00:01,  3.02it/s]\u001b[A\n",
      "Translating de:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 11/15 [00:04<00:01,  3.13it/s]\u001b[A\n",
      "Translating de:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 12/15 [00:04<00:00,  3.78it/s]\u001b[A\n",
      "Translating de:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 13/15 [00:05<00:00,  3.84it/s]\u001b[A\n",
      "Translating de:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/15 [00:05<00:00,  3.72it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:06<00:00,  2.43it/s]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 1/3 [00:00<00:01,  1.12it/s]\u001b[A\n",
      "Translating de:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 2/3 [00:03<00:01,  1.97s/it]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.90s/it]\u001b[A\n",
      "\n",
      "Translating de: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de:   7%|â–ˆâ–Š                          | 1/15 [00:00<00:07,  1.91it/s]\u001b[A\n",
      "Translating de:  13%|â–ˆâ–ˆâ–ˆâ–‹                        | 2/15 [00:00<00:06,  2.04it/s]\u001b[A\n",
      "Translating de:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 3/15 [00:01<00:07,  1.69it/s]\u001b[A\n",
      "Translating de:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 4/15 [00:01<00:05,  2.19it/s]\u001b[A\n",
      "Translating de:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 5/15 [00:02<00:05,  1.78it/s]\u001b[A\n",
      "Translating de:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 6/15 [00:03<00:04,  1.82it/s]\u001b[A\n",
      "Translating de:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 7/15 [00:03<00:04,  1.69it/s]\u001b[A\n",
      "Translating de:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 9/15 [00:04<00:03,  1.85it/s]\u001b[A\n",
      "Translating de:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 10/15 [00:05<00:02,  2.10it/s]\u001b[A\n",
      "Translating de:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 11/15 [00:05<00:01,  2.35it/s]\u001b[A\n",
      "Translating de:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 12/15 [00:08<00:03,  1.14s/it]\u001b[A\n",
      "Translating de:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 13/15 [00:08<00:01,  1.13it/s]\u001b[A\n",
      "Translating de:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/15 [00:10<00:01,  1.25s/it]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:11<00:00,  1.28it/s]\u001b[A\n",
      "Map:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 336/671 [01:40<03:41,  1.51 examples/s]\n",
      "Translating de:   0%|                                     | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de:  11%|â–ˆâ–ˆâ–ˆâ–                         | 1/9 [00:00<00:04,  1.71it/s]\u001b[A\n",
      "Translating de:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 2/9 [00:01<00:04,  1.43it/s]\u001b[A\n",
      "Translating de:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 3/9 [00:02<00:04,  1.40it/s]\u001b[A\n",
      "Translating de:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 4/9 [00:03<00:04,  1.20it/s]\u001b[A\n",
      "Translating de:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 5/9 [00:03<00:03,  1.23it/s]\u001b[A\n",
      "Translating de:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 6/9 [00:04<00:02,  1.25it/s]\u001b[A\n",
      "Translating de:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 7/9 [00:05<00:01,  1.51it/s]\u001b[A\n",
      "Translating de:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 8/9 [00:05<00:00,  1.81it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.49it/s]\u001b[A\n",
      "\n",
      "config.json: 1.42kB [00:00, 8.85MB/s]\n",
      "\n",
      "pytorch_model.bin:   0%|                             | 0.00/301M [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model.bin:   0%|                  | 60.2k/301M [00:00<1:23:06, 60.3kB/s]\u001b[A\n",
      "pytorch_model.bin:   5%|â–‰                   | 14.0M/301M [00:01<00:16, 17.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  15%|â–ˆâ–ˆâ–‰                 | 43.9M/301M [00:01<00:04, 58.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  20%|â–ˆâ–ˆâ–ˆâ–ˆ                | 60.6M/301M [00:01<00:03, 76.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 96.2M/301M [00:01<00:01, 129MB/s]\u001b[A\n",
      "pytorch_model.bin:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 147M/301M [00:01<00:00, 197MB/s]\u001b[A\n",
      "pytorch_model.bin:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 234M/301M [00:01<00:00, 223MB/s]\u001b[A\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 301M/301M [00:02<00:00, 139MB/s]\u001b[A\n",
      "\n",
      "generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 293/293 [00:00<00:00, 3.64MB/s]\u001b[A\n",
      "\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.0/42.0 [00:00<00:00, 520kB/s]\u001b[A\n",
      "\n",
      "model.safetensors:   0%|                             | 0.00/301M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "source.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 802k/802k [00:00<00:00, 213MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "target.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778k/778k [00:00<00:00, 175MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "vocab.json: 1.34MB [00:00, 161MB/s][A\n",
      "\n",
      "model.safetensors:   0%|                    | 1.02M/301M [00:00<04:41, 1.07MB/s]\u001b[ADevice set to use cuda:0\n",
      "\n",
      "model.safetensors:   1%|â–                   | 4.37M/301M [00:01<00:56, 5.24MB/s]\u001b[A\n",
      "model.safetensors:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 99.6M/301M [00:01<00:02, 90.6MB/s]\u001b[A\n",
      "model.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 167M/301M [00:01<00:00, 153MB/s]\u001b[A\n",
      "\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 301M/301M [00:01<00:00, 166MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Translating fr:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 1/6 [00:00<00:01,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Translating fr:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 2/6 [00:00<00:01,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Translating fr:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 3/6 [00:00<00:00,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Translating fr:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 4/6 [00:01<00:00,  3.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Translating fr:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5/6 [00:01<00:00,  4.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Translating de: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating fr: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating de: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating fr: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                     | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de:  11%|â–ˆâ–ˆâ–ˆâ–                         | 1/9 [00:00<00:04,  1.67it/s]\u001b[A\n",
      "Translating de:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 2/9 [00:01<00:05,  1.33it/s]\u001b[A\n",
      "Translating de:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 3/9 [00:02<00:04,  1.33it/s]\u001b[A\n",
      "Translating de:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 4/9 [00:03<00:04,  1.17it/s]\u001b[A\n",
      "Translating de:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 5/9 [00:03<00:03,  1.21it/s]\u001b[A\n",
      "Translating de:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 6/9 [00:04<00:02,  1.25it/s]\u001b[A\n",
      "Translating de:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 7/9 [00:05<00:01,  1.51it/s]\u001b[A\n",
      "Translating de:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 8/9 [00:05<00:00,  1.79it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "\n",
      "Translating fr:   0%|                                     | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 1/6 [00:00<00:01,  3.03it/s]\u001b[A\n",
      "Translating fr:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 2/6 [00:00<00:01,  2.09it/s]\u001b[A\n",
      "Translating fr:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 3/6 [00:01<00:01,  2.59it/s]\u001b[A\n",
      "Translating fr:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 4/6 [00:01<00:00,  3.11it/s]\u001b[A\n",
      "Translating fr:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5/6 [00:01<00:00,  3.77it/s]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.22it/s]\u001b[A\n",
      "Map:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 352/671 [02:01<04:21,  1.22 examples/s]\n",
      "Translating fr:   0%|                                    | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr:   7%|â–ˆâ–ˆ                          | 1/14 [00:00<00:02,  4.36it/s]\u001b[A\n",
      "Translating fr:  14%|â–ˆâ–ˆâ–ˆâ–ˆ                        | 2/14 [00:00<00:02,  4.08it/s]\u001b[A\n",
      "Translating fr:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 3/14 [00:00<00:02,  4.19it/s]\u001b[A\n",
      "Translating fr:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 4/14 [00:00<00:02,  4.65it/s]\u001b[A\n",
      "Translating fr:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 5/14 [00:01<00:02,  3.31it/s]\u001b[A\n",
      "Translating fr:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 6/14 [00:01<00:02,  3.15it/s]\u001b[A\n",
      "Translating fr:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 7/14 [00:01<00:02,  3.38it/s]\u001b[A\n",
      "Translating fr:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 8/14 [00:02<00:01,  3.88it/s]\u001b[A\n",
      "Translating fr:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 9/14 [00:02<00:01,  4.58it/s]\u001b[A\n",
      "Translating fr:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 10/14 [00:02<00:00,  4.24it/s]\u001b[A\n",
      "Translating fr:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 12/14 [00:02<00:00,  4.54it/s]\u001b[A\n",
      "Translating fr:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 13/14 [00:03<00:00,  4.09it/s]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.90it/s]\u001b[A\n",
      "\n",
      "Translating fr:   0%|                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 1/4 [00:00<00:00,  5.26it/s]\u001b[A\n",
      "Translating fr:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 2/4 [00:00<00:00,  2.34it/s]\u001b[A\n",
      "Translating fr:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 3/4 [00:02<00:00,  1.17it/s]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/it]\u001b[A\n",
      "\n",
      "Translating fr: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating fr:   0%|                                    | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr:   7%|â–ˆâ–ˆ                          | 1/14 [00:00<00:02,  4.35it/s]\u001b[A\n",
      "Translating fr:  14%|â–ˆâ–ˆâ–ˆâ–ˆ                        | 2/14 [00:00<00:02,  4.09it/s]\u001b[A\n",
      "Translating fr:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 3/14 [00:00<00:02,  4.20it/s]\u001b[A\n",
      "Translating fr:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 4/14 [00:00<00:02,  4.63it/s]\u001b[A\n",
      "Translating fr:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 5/14 [00:01<00:02,  3.28it/s]\u001b[A\n",
      "Translating fr:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 6/14 [00:01<00:02,  2.68it/s]\u001b[A\n",
      "Translating fr:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 7/14 [00:02<00:02,  2.99it/s]\u001b[A\n",
      "Translating fr:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 8/14 [00:02<00:01,  3.50it/s]\u001b[A\n",
      "Translating fr:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 9/14 [00:03<00:02,  2.39it/s]\u001b[A\n",
      "Translating fr:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 10/14 [00:03<00:01,  2.67it/s]\u001b[A\n",
      "Translating fr:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 12/14 [00:05<00:01,  1.66it/s]\u001b[A\n",
      "Translating fr:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 13/14 [00:07<00:01,  1.04s/it]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.82it/s]\u001b[A\n",
      "Map:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 368/671 [02:16<04:20,  1.16 examples/s]\n",
      "Translating fr:   0%|                                    | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr:   8%|â–ˆâ–ˆâ–                         | 1/13 [00:00<00:02,  5.97it/s]\u001b[A\n",
      "Translating fr:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–                       | 2/13 [00:00<00:02,  4.65it/s]\u001b[A\n",
      "Translating fr:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 3/13 [00:00<00:01,  5.34it/s]\u001b[A\n",
      "Translating fr:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 4/13 [00:00<00:01,  4.57it/s]\u001b[A\n",
      "Translating fr:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 5/13 [00:00<00:01,  5.60it/s]\u001b[A\n",
      "Translating fr:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 6/13 [00:01<00:01,  6.19it/s]\u001b[A\n",
      "Translating fr:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 7/13 [00:01<00:00,  6.98it/s]\u001b[A\n",
      "Translating fr:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 8/13 [00:01<00:00,  6.24it/s]\u001b[A\n",
      "Translating fr:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 9/13 [00:01<00:00,  5.99it/s]\u001b[A\n",
      "Translating fr:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 10/13 [00:01<00:00,  6.70it/s]\u001b[A\n",
      "Translating fr:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/13 [00:01<00:00,  7.36it/s]\u001b[A\n",
      "Translating fr:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 12/13 [00:02<00:00,  5.61it/s]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:02<00:00,  6.04it/s]\u001b[A\n",
      "\n",
      "Translating fr:   0%|                                     | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr:  11%|â–ˆâ–ˆâ–ˆâ–                         | 1/9 [00:04<00:35,  4.42s/it]\u001b[A\n",
      "Translating fr:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 2/9 [00:04<00:13,  1.89s/it]\u001b[A\n",
      "Translating fr:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 3/9 [00:07<00:15,  2.58s/it]\u001b[A\n",
      "Translating fr:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 4/9 [00:11<00:14,  2.81s/it]\u001b[A\n",
      "Translating fr:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 5/9 [00:15<00:13,  3.38s/it]\u001b[A\n",
      "Translating fr:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 6/9 [00:16<00:07,  2.42s/it]\u001b[A\n",
      "Translating fr:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 7/9 [00:19<00:05,  2.63s/it]\u001b[A\n",
      "Translating fr:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 8/9 [00:22<00:02,  2.83s/it]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:25<00:00,  2.83s/it]\u001b[A\n",
      "\n",
      "Translating fr: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating fr:   0%|                                    | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr:   8%|â–ˆâ–ˆâ–                         | 1/13 [00:00<00:02,  5.35it/s]\u001b[A\n",
      "Translating fr:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–                       | 2/13 [00:04<00:29,  2.68s/it]\u001b[A\n",
      "Translating fr:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 3/13 [00:04<00:15,  1.53s/it]\u001b[A\n",
      "Translating fr:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 4/13 [00:05<00:09,  1.05s/it]\u001b[A\n",
      "Translating fr:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 5/13 [00:08<00:15,  1.90s/it]\u001b[A\n",
      "Translating fr:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 6/13 [00:08<00:09,  1.30s/it]\u001b[A\n",
      "Translating fr:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 7/13 [00:11<00:11,  1.97s/it]\u001b[A\n",
      "Translating fr:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 8/13 [00:18<00:17,  3.49s/it]\u001b[A\n",
      "Translating fr:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 9/13 [00:19<00:10,  2.61s/it]\u001b[A\n",
      "Translating fr:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 10/13 [00:22<00:08,  2.73s/it]\u001b[A\n",
      "Translating fr:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/13 [00:25<00:05,  2.81s/it]\u001b[A\n",
      "Translating fr:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 12/13 [00:25<00:02,  2.05s/it]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:28<00:00,  2.22s/it]\u001b[A\n",
      "Map:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 384/671 [03:13<07:30,  1.57s/ examples]\n",
      "Translating fr:   0%|                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                        | 1/7 [00:00<00:01,  5.61it/s]\u001b[A\n",
      "Translating fr:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 2/7 [00:00<00:00,  7.40it/s]\u001b[A\n",
      "Translating fr:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 3/7 [00:00<00:00,  5.40it/s]\u001b[A\n",
      "Translating fr:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 4/7 [00:00<00:00,  4.20it/s]\u001b[A\n",
      "Translating fr:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 5/7 [00:00<00:00,  5.26it/s]\u001b[A\n",
      "Translating fr:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 6/7 [00:01<00:00,  4.91it/s]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.72it/s]\u001b[A\n",
      "\n",
      "Translating fr:   0%|                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 1/3 [00:04<00:09,  4.80s/it]\u001b[A\n",
      "Translating fr:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 2/3 [00:07<00:03,  3.73s/it]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:11<00:00,  3.67s/it]\u001b[A\n",
      "\n",
      "Translating fr: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating fr:   0%|                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                        | 1/7 [00:00<00:01,  5.59it/s]\u001b[A\n",
      "Translating fr:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 2/7 [00:03<00:11,  2.21s/it]\u001b[A\n",
      "Translating fr:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 3/7 [00:04<00:05,  1.31s/it]\u001b[A\n",
      "Translating fr:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 4/7 [00:04<00:02,  1.08it/s]\u001b[A\n",
      "Translating fr:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 5/7 [00:07<00:03,  1.74s/it]\u001b[A\n",
      "Translating fr:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 6/7 [00:14<00:03,  3.46s/it]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:14<00:00,  2.09s/it]\u001b[A\n",
      "Map:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 400/671 [03:40<07:15,  1.61s/ examples]\n",
      "Translating es:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.85it/s]\u001b[A\n",
      "\n",
      "Translating es: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating es: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating es:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.77it/s]\u001b[A\n",
      "Map:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 432/671 [03:40<03:36,  1.11 examples/s]\n",
      "Translating fr:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.42it/s]\u001b[A\n",
      "\n",
      "Translating fr: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating fr: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating fr:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.40it/s]\u001b[A\n",
      "Map:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 512/671 [03:41<00:56,  2.80 examples/s]\n",
      "Translating de:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.52it/s]\u001b[A\n",
      "\n",
      "config.json: 1.38kB [00:00, 7.45MB/s]\n",
      "\n",
      "pytorch_model.bin:   0%|                             | 0.00/303M [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model.bin:   7%|â–ˆâ–                   | 21.0M/303M [00:00<00:01, 149MB/s]\u001b[A\n",
      "pytorch_model.bin:  14%|â–ˆâ–ˆâ–‰                  | 41.9M/303M [00:00<00:01, 174MB/s]\u001b[A\n",
      "pytorch_model.bin:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 73.4M/303M [00:00<00:01, 224MB/s]\u001b[A\n",
      "pytorch_model.bin:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 105M/303M [00:00<00:00, 253MB/s]\u001b[A\n",
      "pytorch_model.bin:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 147M/303M [00:00<00:00, 280MB/s]\u001b[A\n",
      "pytorch_model.bin:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 189M/303M [00:00<00:00, 296MB/s]\u001b[A\n",
      "pytorch_model.bin:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/303M [00:00<00:00, 306MB/s]\u001b[A\n",
      "pytorch_model.bin:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 262M/303M [00:00<00:00, 308MB/s]\u001b[A\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 303M/303M [00:01<00:00, 278MB/s]\u001b[A\n",
      "\n",
      "generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 293/293 [00:00<00:00, 3.10MB/s]\u001b[A\n",
      "\n",
      "model.safetensors:   0%|                             | 0.00/303M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.0/42.0 [00:00<00:00, 437kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:   7%|â–ˆâ–                   | 21.0M/303M [00:00<00:01, 158MB/s]\u001b[A\n",
      "model.safetensors:  14%|â–ˆâ–ˆâ–‰                  | 41.9M/303M [00:00<00:01, 164MB/s]\u001b[A\n",
      "\n",
      "source.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782k/782k [00:00<00:00, 195MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 73.4M/303M [00:00<00:01, 216MB/s]\u001b[A\n",
      "model.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 115M/303M [00:00<00:00, 265MB/s]\u001b[A\n",
      "model.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 157M/303M [00:00<00:00, 296MB/s]\u001b[A\n",
      "model.safetensors:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 199M/303M [00:00<00:00, 304MB/s]\u001b[A\n",
      "model.safetensors:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 231M/303M [00:00<00:00, 304MB/s]\u001b[A\n",
      "\n",
      "target.spm: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 802k/802k [00:00<00:00, 165MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 273M/303M [00:00<00:00, 313MB/s]\u001b[A\n",
      "\n",
      "vocab.json: 1.50MB [00:00, 118MB/s][A\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 303M/303M [00:01<00:00, 280MB/s]\n",
      "Device set to use cuda:0\n",
      "\n",
      "Translating ja:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating ja: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.55it/s]\u001b[A\n",
      "\n",
      "Translating es:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.46it/s]\u001b[A\n",
      "\n",
      "Translating de: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating ja: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating es: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating de: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating ja: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating es: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.60it/s]\u001b[A\n",
      "\n",
      "Translating ja:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating ja: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.76it/s]\u001b[A\n",
      "\n",
      "Translating es:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating es: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.46it/s]\u001b[A\n",
      "Map:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 560/671 [03:47<00:30,  3.66 examples/s]\n",
      "Translating fr:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.62it/s]\u001b[A\n",
      "\n",
      "Translating fr: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating de: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating fr: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Translating de: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Map:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 560/671 [03:58<00:30,  3.66 examples/s]\u001b[A\n",
      "Translating fr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.56s/it]\u001b[A\n",
      "\n",
      "Translating de:   0%|                                     | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Translating de: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.29it/s]\u001b[A\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 671/671 [04:00<00:00,  2.79 examples/s]\n",
      "Creating json from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.02ba/s]\n",
      "[INFO] Wrote language-normalized data to /kaggle/working/sportsoracle/data/raw_combined_en.jsonl\n",
      "[3/5] Embedding and clustering posts (per category)...\n",
      "Generating train split: 671 examples [00:00, 56332.63 examples/s]\n",
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 671/671 [00:00<00:00, 35721.80 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 671/671 [00:00<00:00, 28992.69 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 671/671 [00:00<00:00, 24245.99 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 671/671 [00:00<00:00, 5295.56 examples/s]\n",
      "Processing category: nba (posts: 247)\n",
      "modules.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 349/349 [00:00<00:00, 2.23MB/s]\n",
      "config_sentence_transformers.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 969kB/s]\n",
      "README.md: 10.4kB [00:00, 33.2MB/s]\n",
      "sentence_bert_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53.0/53.0 [00:00<00:00, 459kB/s]\n",
      "config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 571/571 [00:00<00:00, 3.93MB/s]\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438M/438M [00:02<00:00, 218MB/s]\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 363/363 [00:00<00:00, 4.28MB/s]\n",
      "vocab.txt: 232kB [00:00, 123MB/s]\n",
      "tokenizer.json: 466kB [00:00, 143MB/s]\n",
      "special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 239/239 [00:00<00:00, 2.30MB/s]\n",
      "config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:00<00:00, 1.55MB/s]\n",
      "Embedding on device: cuda\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.22it/s]\n",
      "Saved embeddings, labels, metadata, clusters for category: nba\n",
      "Saved UMAP scatterplot and barchart to outputs/bertopic_viz_nba\n",
      "Saved BERTopic visualizations for category: nba to outputs/bertopic_viz_nba\n",
      "Processing category: soccer (posts: 394)\n",
      "Embedding on device: cuda\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.16it/s]\n",
      "Saved embeddings, labels, metadata, clusters for category: soccer\n",
      "Saved UMAP scatterplot and barchart to outputs/bertopic_viz_soccer\n",
      "Saved BERTopic visualizations for category: soccer to outputs/bertopic_viz_soccer\n",
      "Pipeline complete for all categories: ['nba', 'soccer']\n",
      "[4/5] Summarizing clusters and generating trends_summary.json...\n",
      "config.json: 1.58kB [00:00, 10.4MB/s]\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.63G/1.63G [00:06<00:00, 244MB/s]\n",
      "generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 363/363 [00:00<00:00, 2.74MB/s]\n",
      "vocab.json: 899kB [00:00, 132MB/s]\n",
      "merges.txt: 456kB [00:00, 89.9MB/s]\n",
      "tokenizer.json: 1.36MB [00:00, 113MB/s]\n",
      "Device set to use cuda:0\n",
      "Generating train split: 247 examples [00:00, 23780.40 examples/s]\n",
      "Your max_length is set to 80, but your input_length is only 62. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=31)\n",
      "Generating train split: 394 examples [00:00, 59611.71 examples/s]\n",
      "Your max_length is set to 80, but your input_length is only 70. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n",
      "Wrote cluster summaries to /kaggle/working/sportsoracle/outputs/trends_summary.json\n",
      "[5/5] Building FAISS indexes for NBA and soccer...\n",
      "FAISS index and mapping saved to /kaggle/working/sportsoracle/data/faiss_nba.index, /kaggle/working/sportsoracle/data/index_mapping_nba.json\n",
      "FAISS index and mapping saved to /kaggle/working/sportsoracle/data/faiss_soccer.index, /kaggle/working/sportsoracle/data/index_mapping_soccer.json\n",
      "\n",
      "âœ… SportsOracle pipeline complete. trends_summary.json and FAISS indexes are ready for your dashboard and search.\n",
      "\n",
      "\u001b[0m\n",
      "real\t6m35.144s\n",
      "user\t5m40.114s\n",
      "sys\t0m38.346s\n"
     ]
    }
   ],
   "source": [
    "# â–¶ï¸ 4.  Run the entire pipeline (scrape âœ embed âœ cluster âœ summarize )\n",
    "\n",
    "!time python /kaggle/working/sportsoracle/main.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
